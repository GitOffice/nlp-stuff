{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: to run the notebooks move them to the main dir. Simply\n",
    "\n",
    "```bash\n",
    "cp notebook_name.ipynd ../\n",
    "```\n",
    "\n",
    "So far, in notebooks 01 and 02 I have described how to prepare the data and to implement a Hierarchical Attention Network to classify amazon reviews. Here I will describe how to run the experiments. \n",
    "\n",
    "Let's start by importing the neccesary tooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from models.pytorch_models import HierAttnNet, RNNAttn\n",
    "from utils.metrics import CategoricalAccuracy\n",
    "from utils.parser import parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cpus = os.cpu_count()\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"data\")\n",
    "train_dir = data_dir / \"train\"\n",
    "valid_dir = data_dir / \"valid\"\n",
    "test_dir = data_dir / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain, fvalid, ftest = \"han_train.npz\", \"han_valid.npz\", \"han_test.npz\"\n",
    "tokf = \"HANPreprocessor.p\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with other notebooks, and to keep the data size tractable, I will just just a sample of 1000 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_mtx = np.load(train_dir / ftrain)\n",
    "np.random.seed(1)\n",
    "idx = np.random.choice(train_mtx[\"X_train\"].shape[0], 1000)\n",
    "train_set = TensorDataset(\n",
    "    torch.from_numpy(train_mtx[\"X_train\"][idx]),\n",
    "    torch.from_numpy(train_mtx[\"y_train\"][idx]).long(),\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, num_workers=n_cpus)\n",
    "\n",
    "valid_mtx = np.load(valid_dir / fvalid)\n",
    "np.random.seed(2)\n",
    "idx = np.random.choice(valid_mtx[\"X_valid\"].shape[0], 1000)\n",
    "eval_set = TensorDataset(\n",
    "    torch.from_numpy(valid_mtx[\"X_valid\"][idx]),\n",
    "    torch.from_numpy(valid_mtx[\"y_valid\"][idx]).long(),\n",
    ")\n",
    "eval_loader = DataLoader(\n",
    "    dataset=eval_set, batch_size=batch_size, num_workers=n_cpus, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[   1,    1,    1,  ...,   70,   88,    9],\n",
       "          [   1,    1,    1,  ...,   35, 3007,  841],\n",
       "          [   1,    1,    1,  ...,  222,   70,    9],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         [[   1,    1,    1,  ...,  109,   15,    9],\n",
       "          [   1,    1,    1,  ...,   22, 1108,    9],\n",
       "          [   1,    1,    1,  ...,  448,  144, 1587],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         [[   1,    1,    1,  ...,   10, 6706,    9],\n",
       "          [   1,    1,    1,  ...,    5,   97,    9],\n",
       "          [   1,    1,    1,  ...,   66,  186,    9],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[   1,    1,    1,  ...,    6,   44,    9],\n",
       "          [   6,   59,    6,  ...,    6,  191,    9],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         [[   1,    1,    1,  ...,   72,  208,    9],\n",
       "          [   1,    1,    1,  ...,   70,   28,    9],\n",
       "          [   1,    1,    1,  ...,   30,   30,   30],\n",
       "          ...,\n",
       "          [ 931, 3086, 1693,  ...,  138,  147,    9],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]],\n",
       " \n",
       "         [[   1,    1,    1,  ...,   27,  114,    9],\n",
       "          [   1,    1,    1,  ..., 7355,   38,    9],\n",
       "          [   1,    1,    1,  ...,   19,   10,  431],\n",
       "          ...,\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]]], dtype=torch.int32),\n",
       " tensor([3, 3, 3, 3, 3, 3, 0, 2, 3, 2, 3, 3, 1, 2, 3, 2, 3, 3, 1, 3, 2, 3, 0, 3,\n",
       "         3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 2, 2, 3, 3, 1, 3, 2, 3, 3, 2, 0, 3, 0,\n",
       "         3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = pickle.load(open(data_dir / tokf, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.preprocessors.HANPreprocessor at 0x13856d208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HierAttnNet(\n",
    "    vocab_size=len(tok.vocab.stoi),\n",
    "    maxlen_sent=tok.maxlen_sent,\n",
    "    maxlen_doc=tok.maxlen_doc,\n",
    "    word_hidden_dim=32,\n",
    "    sent_hidden_dim=32,\n",
    "    padding_idx=1,\n",
    "    embed_dim=50,\n",
    "    weight_drop=0.,\n",
    "    embed_drop=0.,\n",
    "    locked_drop=0.,\n",
    "    last_drop=0.,\n",
    "    embedding_matrix=None,\n",
    "    num_class=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierAttnNet(\n",
       "  (wordattnnet): WordAttnNet(\n",
       "    (lockdrop): LockedDropout()\n",
       "    (word_embed): Embedding(23611, 50, padding_idx=1)\n",
       "    (rnn): GRU(50, 32, batch_first=True, bidirectional=True)\n",
       "    (word_attn): AttentionWithContext(\n",
       "      (attn): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (contx): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (sentattnnet): SentAttnNet(\n",
       "    (rnn): GRU(64, 32, batch_first=True, bidirectional=True)\n",
       "    (sent_attn): AttentionWithContext(\n",
       "      (attn): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (contx): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (ld): Dropout(p=0.0, inplace=False)\n",
       "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I move forward let me comment on the dropout-related parameters. You will see 4 types of dropout:\n",
    "\n",
    "1. `embed_drop`\n",
    "2. `weight_drop`\n",
    "3. `locked_drop`\n",
    "4. `last_drop`\n",
    "\n",
    "The first 3 are taken directly from the work of Stephen Merity, Nitish Shirish Keskar and Richard Socher in their 2017 [paper](https://arxiv.org/pdf/1708.02182.pdf): *Regularizing and Optimizing LSTM Language Models*. \n",
    "\n",
    "In fact, within the `models` module there are 3 submodules named: `embed_regularize.py`, `locked_dropout.py` and `weight_dropout.py`. The code in there is **taken directly** from the original implementation at the [Salesforce repo](https://github.com/salesforce/awd-lstm-lm). The adaptations are minimal, simply adjusting the code to newer versions of `Pytorch` and a few minor style-related changes. Other than that, is a \"copy-paste\" of the code in their repo, so all credit to the 3 authors of the paper and the code. The `last_drop` is simply dropout before the last fully connected layer.\n",
    "\n",
    "It is beyond the scope of this notebook to dive into the details of these dropouts methods. I intend to write a companion Medium post where I will discuss them in more detail, although in all honesty, they are simple, brilliant ideas to apply regularization. I'd say that you would easily understand what these methods do by having a quick look to the code that the authors wrote and also, of course, read the paper. \n",
    "\n",
    "The reason to add this much dropout is because when I started running experiments I noticed that the model overfitted quite early. In fact, in some cases, the best validation loss was attained in the very first epoch. \n",
    "\n",
    "When overfitting occurs, one has 3 options to avoid it:\n",
    "\n",
    "1. Reduce model complexity\n",
    "2. Early Stop (although if the process stops in a suboptimal solution, this only guarantess that we will not be using a worse solution, but it will not solve the problem that the current solution is indeed suboptimal model)\n",
    "3. Regularization\n",
    "\n",
    "The first two are a given, via parameter space exploration and a standard Early Stop function I implemented. To account for the 3rd one, I used the before mentioned dropout mechanisms. \n",
    "\n",
    "Note that there are other implementations of these dropout mechanisms other than the original (and inspired by that one, of course). For example, the `text` API at the fastai library has a very neat [implementation](https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L75). Another nice [implemenation](https://github.com/dmlc/gluon-nlp/blob/8869e795b683ff52073b556cd24e1d06cf9952ac/src/gluonnlp/model/utils.py#L34) is found at the `Mxnet's` `gluonnlp` library, which I have also used here $-$ although only the `Pytorch` implementation is discussed here, I have also implemented the full HAN model using `Mxnet` $-$. \n",
    "\n",
    "Having said all of the above, let's move on, shall we? \n",
    "\n",
    "Once we have the model, we need the remaining Pytorch components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "# This class is at the utils module\n",
    "metric = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the standard train and validation steps, along with an early stop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, train_loader, epoch, metric):\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    train_steps = len(train_loader)\n",
    "    running_loss = 0\n",
    "    with trange(train_steps) as t:\n",
    "        for batch_idx, (data, target) in zip(t, train_loader):\n",
    "            t.set_description(\"epoch %i\" % (epoch + 1))\n",
    "\n",
    "            X = data.cuda() if use_cuda else data\n",
    "            y = target.cuda() if use_cuda else target\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            acc = metric(F.softmax(y_pred, dim=1), y)\n",
    "\n",
    "            t.set_postfix(acc=acc, loss=avg_loss)\n",
    "\n",
    "\n",
    "def eval_step(model, eval_loader, metric, is_test=False):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    eval_steps = len(eval_loader)\n",
    "    running_loss = 0\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        with trange(eval_steps) as t:\n",
    "            for batch_idx, (data, target) in zip(t, eval_loader):\n",
    "                if is_test:\n",
    "                    t.set_description(\"test\")\n",
    "                else:\n",
    "                    t.set_description(\"valid\")\n",
    "\n",
    "                X = data.cuda() if use_cuda else data\n",
    "                y = target.cuda() if use_cuda else target\n",
    "\n",
    "                y_pred = model(X)\n",
    "                loss = F.cross_entropy(y_pred, y)\n",
    "                running_loss += loss.item()\n",
    "                avg_loss = running_loss / (batch_idx + 1)\n",
    "                acc = metric(F.softmax(y_pred, dim=1), y)\n",
    "                if is_test:\n",
    "                    preds.append(y_pred)\n",
    "                t.set_postfix(acc=acc, loss=avg_loss)\n",
    "\n",
    "    return avg_loss, preds\n",
    "\n",
    "\n",
    "def early_stopping(curr_value, best_value, stop_step, patience):\n",
    "    if curr_value <= best_value:\n",
    "        stop_step, best_value = 0, curr_value\n",
    "    else:\n",
    "        stop_step += 1\n",
    "    if stop_step >= patience:\n",
    "        print(\"Early stopping triggered. log:{}\".format(best_value))\n",
    "        stop = True\n",
    "    else:\n",
    "        stop = False\n",
    "    return best_value, stop_step, stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that we are good to go. Note that one could just define the train/eval functions so that they run all the epochs. Normally I prefer to code the steps and run them in a loop. A matter of taste, also depends on the code structure. In this particular case, I will leave it as it is. \n",
    "\n",
    "To run the model simply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 16/16 [00:04<00:00,  3.73it/s, acc=0.542, loss=1.25]\n",
      "valid: 100%|██████████| 16/16 [00:00<00:00, 18.30it/s, acc=0.577, loss=1.15]\n",
      "epoch 2: 100%|██████████| 16/16 [00:04<00:00,  3.76it/s, acc=0.584, loss=1.12]\n",
      "valid: 100%|██████████| 16/16 [00:00<00:00, 18.35it/s, acc=0.577, loss=1.12]\n",
      "epoch 3: 100%|██████████| 16/16 [00:04<00:00,  3.73it/s, acc=0.584, loss=1.09]\n",
      "valid: 100%|██████████| 16/16 [00:00<00:00, 18.47it/s, acc=0.577, loss=1.11]\n",
      "epoch 4: 100%|██████████| 16/16 [00:04<00:00,  3.77it/s, acc=0.584, loss=1.08]\n",
      "valid: 100%|██████████| 16/16 [00:00<00:00, 18.60it/s, acc=0.577, loss=1.09]\n"
     ]
    }
   ],
   "source": [
    "metric = CategoricalAccuracy()\n",
    "n_epochs = 4\n",
    "eval_every = 1\n",
    "patience = 1\n",
    "stop_step = 0\n",
    "best_loss = 1e6\n",
    "for epoch in range(n_epochs):\n",
    "    train_step(model, optimizer, train_loader, epoch, metric)\n",
    "    if epoch % eval_every == (eval_every - 1):\n",
    "        val_loss, _ = eval_step(model, eval_loader, metric)\n",
    "        best_loss, stop_step, stop = early_stopping(\n",
    "            val_loss, best_loss, stop_step, patience\n",
    "        )\n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. If you have a look to the `run_pytorch.py` script you will see that, of course, there are a number of additional adds on to the training/validation/test process, but the main bits and pieces have been discussed here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
